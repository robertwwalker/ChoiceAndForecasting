{
  "hash": "def5dbbcd4cb5cf41b15f1e02355313b",
  "result": {
    "markdown": "---\ntitle: \"Week 5: Hierarchical Data\"\nauthor: \"Robert W. Walker\"\ndate: \"2022-09-26\"\ncategories: [R]\nimage: \"image.png\"\ntoc: true\nexecute: \n  echo: fenced\n---\n\n\nThe slides [are here.](https://robertwwalker.github.io/xaringan/CMF-Week-5/).\n\nOur fifth class meeting will focus on [Chapter 8](https://peopleanalytics-regression-book.org/gitbook/modeling-explicit-and-latent-hierarchy-in-data.html) of __Handbook of Regression Modeling in People Analytics__. \n\n## The Skinny\n\nHierarchical models represent an advance on more standard linear and generalized linear models with the recognition that data have hierarchical forms of organization with varying degrees of freedom for the predictors.  These models can, generically, be combined with techniques that we have already learned to expand the range of our toolkit.  Since we left last week off with ordered models, they will first occupy our attention.\n\n## Ordered Models\n\nMy preferred method of thinking about ordered regression involves latent variables.  So what is a latent variable?  It is something that is unobservable, hence latent, and we only observe coarse realizations in the form of qualitative categories.  Consider the example from [Li in the *Journal of Politics*](https://www.journals.uchicago.edu/doi/abs/10.1111/j.1468-2508.2006.00370.x).\n\n![Li Abstract](./data/Screen Shot 2022-09-19 at 9.59.09 AM.png)\n\n\n\n## The Outcome\n\nThe outcome is summed from six individual types of incentives.  They are explained here.\n\n![Tax Incentives to FDI](./data/Screen Shot 2022-09-19 at 10.09.08 AM.png)\n\nand\n\n![Tax Incentives Part 2](./data/Screen Shot 2022-09-19 at 10.10.30 AM.png)\n\n## Inputs\n\nThere are two parts to the data description for the inputs.\n\n![Part 1](./data/Screen Shot 2022-09-19 at 10.01.12 AM.png)\n\nand ![Part 2](./data/Screen Shot 2022-09-19 at 10.01.32 AM.png)\n\nand there is a further description of other variables that are deployed.\n\n![Controls: Part 1](./data/Screen Shot 2022-09-19 at 10.17.41 AM.png)\n\nand\n\n![Controls: Part 2](./data/Screen Shot 2022-09-19 at 10.18.53 AM.png)\n\n## The Data\n\nThis should give us an idea of what is going on.  The data come in Stata format; we can read these via the `foreign` or `haven` libraries in R.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nlibrary(MASS); library(foreign)\nLi.Data <- read.dta(\"./data/li-replication.dta\")\ntable(Li.Data$generosityg)\nLi.Data$generositygF <- as.factor(Li.Data$generosityg)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n```\n\n 0  1  2  3  4  5  6 \n13 10 19  7  2  1  1 \n```\n:::\n:::\n\nIt is worthwhile to notice that the top of the scale is rather sparse.\n\nThere is also a concern about FDI and economies of scale.  The following is a plot of the relationship between FDI and size of the economy in the sample.\n\n![FD-Size](./data/size-fdi.png)\n\nWithout careful attention to normalization, China is a clear `x-y` outlier.\n\n## Motivating the Model\n\nSuppose there is some unobserved continuous variable, call it $y^{*}$ that measures the willingness/utility to be derived from tax incentives to FDI.  Unfortunately, this latent quantity is unobservable; we instead observe how many incentives are offered and posit that the number of incentives is a manifestation of increasing utility with unknown points of separation -- cutpoints -- that separate these latent utilities into a mutually exclusive and exhaustive partition.  In a simplified example, consider this.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nplot(density(rlogis(1000)))\nabline(v=c(-3,-2,-1,0,2,4))\n```\n````\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nSo anything below -3 is zero incentives; anything between -3 and -2 is one incentive, ... , and anything above 4 should be all six incentives.  What we have is a regression problem but the outcome is unobserved and takes the form of a logistic random variable.  Indeed, one could write the equation as:\n\n\n$$y^{*} = X\\beta + \\epsilon$$\n\nwhere $\\epsilon$ is assumed to have a logistic distribution but this is otherwise just a linear regression.  Indeed, the direct interpretation of the slopes is the effect of a one-unit change in X on that logistic random variable.\n\n## What to Replicate\n\nThe table of estimates is presented in the paper; I will copy it here.\n\n![Results Table](./data/Screen Shot 2022-09-19 at 10.24.19 AM.png)\n\nI will choose two of a few models estimated in the paper.  First, let us have a look at Model 1.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nli.mod1 <- polr(generositygF ~ law00log + transition, data=Li.Data)\nsummary(li.mod1)\n```\n````\n\n::: {.cell-output .cell-output-stderr}\n```\n\nRe-fitting to get Hessian\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nCall:\npolr(formula = generositygF ~ law00log + transition, data = Li.Data)\n\nCoefficients:\n             Value Std. Error t value\nlaw00log   -0.6192     0.4756 -1.3019\ntransition -0.5161     0.7126 -0.7243\n\nIntercepts:\n    Value   Std. Error t value\n0|1 -1.3617  0.3768    -3.6144\n1|2 -0.4888  0.3323    -1.4707\n2|3  1.1785  0.3668     3.2133\n3|4  2.3771  0.5361     4.4339\n4|5  3.1160  0.7325     4.2541\n5|6  3.8252  1.0183     3.7565\n\nResidual Deviance: 164.3701 \nAIC: 180.3701 \n```\n:::\n:::\n\n\nWe can read these by stars.  There is nothing that is clearly different from zero as a slope or 1 as an odds-ratio.  The authors deploy a common strategy for adjusting standard errors that, in this case, is necessary to find a relationship with statistical confidence.  That's a diversion.  To the story.  In general, the sign of the rule of law indicator is negative, so as rule of law increases, incentives decrease though we cannot rule out no effect.  Transitions also have a negative sign; regime changes have no clear influence on incentives.  There is additional information that is commonly given short-shrift.  What do the cutpoints separating the categories imply?  Let's think this through recongizing that the estimates have an underlying t/normal distribution.  `4|5` is within one standard error of both `3|4` and `5|6`.  The model cannot really tell these values apart.  Things do improve in the lower part of the scale but we should note that this is where the vast majority of the data are actually observed.\n\n### Odds Ratios\n\nNext, I will turn the estimates into odds-ratios by exponentiating the estimates.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nexp(li.mod1$coefficients)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n```\n  law00log transition \n 0.5384016  0.5968309 \n```\n:::\n:::\n\n\nFor Kawika, this is one of the many cases that I am familiar with where `robust` is necessary to find something.  Note neither effect can be differentiated from zero with much confidence at all.  To further examine the claims, I will also replicate the right-most column.\n\n## Column 4 Estimates\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nli.mod4 <- polr(generositygF ~ law00log + transition + fdiinf + democfdi + democ + autocfdi2 + autocfdir + reggengl + reggengl2 + gdppclog + gdplog, data=Li.Data)\nsummary(li.mod4)\n```\n````\n\n::: {.cell-output .cell-output-stderr}\n```\n\nRe-fitting to get Hessian\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nCall:\npolr(formula = generositygF ~ law00log + transition + fdiinf + \n    democfdi + democ + autocfdi2 + autocfdir + reggengl + reggengl2 + \n    gdppclog + gdplog, data = Li.Data)\n\nCoefficients:\n              Value Std. Error t value\nlaw00log   -0.89148    0.66806 -1.3344\ntransition -0.57123    0.94945 -0.6016\nfdiinf      0.37605    0.18055  2.0828\ndemocfdi   -0.39969    0.18228 -2.1927\ndemoc      -1.23307    0.77661 -1.5878\nautocfdi2   1.24932    1.94198  0.6433\nautocfdir  -3.17796    1.95351 -1.6268\nreggengl    1.81476    0.44754  4.0550\nreggengl2  -0.05777    0.01444 -4.0007\ngdppclog    0.20891    0.43867  0.4762\ngdplog      0.15754    0.18138  0.8686\n\nIntercepts:\n    Value    Std. Error t value \n0|1  13.7773   0.1020   135.0542\n1|2  14.7314   0.3048    48.3349\n2|3  16.9740   0.5230    32.4561\n3|4  18.7911   0.8027    23.4107\n4|5  20.0387   1.1590    17.2900\n5|6  23.2947   4.7216     4.9336\n\nResidual Deviance: 134.2212 \nAIC: 168.2212 \n(2 observations deleted due to missingness)\n```\n:::\n:::\n\n\nMeasured via odds-ratios, we can obtain those:\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nexp(li.mod4$coefficients)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n```\n  law00log transition     fdiinf   democfdi      democ  autocfdi2  autocfdir \n0.41004648 0.56483013 1.45651991 0.67052543 0.29139805 3.48796970 0.04167039 \n  reggengl  reggengl2   gdppclog     gdplog \n6.13958891 0.94386864 1.23232943 1.17063051 \n```\n:::\n:::\n\n\n## Diagnostics and Commentary\n\nGoodness of Fit:\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nDescTools::PseudoR2(\n  li.mod1, \n  which = c(\"McFadden\", \"CoxSnell\", \"Nagelkerke\", \"AIC\")\n)\nDescTools::PseudoR2(\n  li.mod4, \n  which = c(\"McFadden\", \"CoxSnell\", \"Nagelkerke\", \"AIC\")\n)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n```\n    McFadden     CoxSnell   Nagelkerke          AIC \n  0.01104919   0.03405653   0.03560378 180.37009764 \n   McFadden    CoxSnell  Nagelkerke         AIC \n  0.1649728   0.4054507   0.4235700 168.2212440 \n```\n:::\n:::\n\nThe last model is clearly better than the first by any of these measures.  That said, there are a lot of additional predictors that add much complexity to the model and the difference in AIC is not very large.\n\nWhat about the others?\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n# lipsitz test \n# generalhoslem::lipsitz.test(li.mod1)\n# generalhoslem::lipsitz.test(li.mod4)\n```\n````\n:::\n\n\nThey fail to work because of sparseness.\n\n### Testing Proportional-Odds\n\nThe text cites a test that owes to Brant on examining proportionality.  It turns out that I know a bit about this; I published a purely theoretical stats paper showing that it is not at all clear what the alternative hypothesis embodied in this test actually means because the only model with a proper probability distribution for $y^{*}$ is this proportional-odds model.\n\nI will follow the text with this caveat in mind:\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nbrant::brant(li.mod1)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n```\n-------------------------------------------- \nTest for\tX2\tdf\tprobability \n-------------------------------------------- \nOmnibus\t\t13.51\t10\t0.2\nlaw00log\t8.64\t5\t0.12\ntransition\t4.28\t5\t0.51\n-------------------------------------------- \n\nH0: Parallel Regression Assumption holds\n```\n:::\n:::\n\n\n### How Well Does the Model Predict?\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nMat.Fit <- data.frame(fitted(li.mod4))\nlibrary(tidyverse)\n```\n````\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.1\n✔ readr   2.1.2     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n✖ dplyr::select() masks MASS::select()\n```\n:::\n\n````{.cell-code}\n```{{r}}\nMat.Fit$pred.val <- rep(-999, 51)\nMat.Fit$pred.val[Mat.Fit$X0 > Mat.Fit$X1 & Mat.Fit$X0 > Mat.Fit$X2 & Mat.Fit$X0 > Mat.Fit$X3 & Mat.Fit$X0 > Mat.Fit$X4 & Mat.Fit$X0 > Mat.Fit$X5 & Mat.Fit$X0 > Mat.Fit$X6] <- 0\nMat.Fit$pred.val[Mat.Fit$X1 > Mat.Fit$X0 & Mat.Fit$X1 > Mat.Fit$X2 & Mat.Fit$X1 > Mat.Fit$X3 & Mat.Fit$X1 > Mat.Fit$X4 & Mat.Fit$X1 > Mat.Fit$X5 & Mat.Fit$X1 > Mat.Fit$X6] <- 1\nMat.Fit$pred.val[Mat.Fit$X2 > Mat.Fit$X0 & Mat.Fit$X2 > Mat.Fit$X1 & Mat.Fit$X2 > Mat.Fit$X3 & Mat.Fit$X2 > Mat.Fit$X4 & Mat.Fit$X2 > Mat.Fit$X5 & Mat.Fit$X2 > Mat.Fit$X6] <- 2\nMat.Fit$pred.val[Mat.Fit$X3 > Mat.Fit$X0 & Mat.Fit$X3 > Mat.Fit$X1 & Mat.Fit$X3 > Mat.Fit$X2 & Mat.Fit$X3 > Mat.Fit$X4 & Mat.Fit$X3 > Mat.Fit$X5 & Mat.Fit$X3 > Mat.Fit$X6] <- 3\nMat.Fit$pred.val[Mat.Fit$X5 > Mat.Fit$X0 & Mat.Fit$X5 > Mat.Fit$X1 & Mat.Fit$X5 > Mat.Fit$X2 & Mat.Fit$X5 > Mat.Fit$X3 & Mat.Fit$X5 > Mat.Fit$X4 & Mat.Fit$X5 > Mat.Fit$X6] <- 5\nMat.Fit$pred.val[Mat.Fit$X6 > Mat.Fit$X0 & Mat.Fit$X6 > Mat.Fit$X1 & Mat.Fit$X6 > Mat.Fit$X2 & Mat.Fit$X6 > Mat.Fit$X3 & Mat.Fit$X6 > Mat.Fit$X4 & Mat.Fit$X6 > Mat.Fit$X5] <- 6\nPred.Data <- Li.Data[c(1:28,30:41,43:53),]\ntable(Pred.Data$generosityg,Mat.Fit$pred.val)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n```\n   \n     0  2  3  6\n  0  6  7  0  0\n  1  5  4  0  0\n  2  5 12  1  0\n  3  1  2  4  0\n  4  0  1  1  0\n  5  0  1  0  0\n  6  0  0  0  1\n```\n:::\n:::\n\n\nSo `6+12+4+1` or 23 of 51 are correctly predicted with a rather big and complicated model.\n\n### On AIC\n\nThe AIC [and BIC] are built around the idea of likelihood presented last time.  The formal definition, [which is correct on Wikipedia](https://en.wikipedia.org/wiki/Akaike_information_criterion) explains the following:\n\n![AIC](./data/Screen Shot 2022-09-19 at 12.06.24 PM.png)\n\n## Hierarchical Models and SEM\n\n\n### Hierarchical Models\n\nTo examine a hierarchical model, I am going to choose some interesting data on popularity.  A description appears below; these data come from an Intro to Multilevel Analysis.\n\n![Popularity Data](./data/Screen Shot 2022-09-26 at 2.13.53 PM.png)\n\nThough the data are technically ordered, this feature is not exploited to build a hierarchical ordered regression model, though it could be done.  Instead, the outcome of interest is an average of *ordered scales*.\n\n### Load the data\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nlibrary(tidyverse)\nlibrary(haven)\npopular2data <- read_sav(file =\"https://github.com/MultiLevelAnalysis/Datasets-third-edition-Multilevel-book/blob/master/chapter%202/popularity/SPSS/popular2.sav?raw=true\")\npopular2data <- popular2data %>% dplyr::select(pupil, class, extrav, sex, texp, popular)\n```\n````\n:::\n\n\n\n### A Summary\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nsummary(popular2data)\nhead(popular2data)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n```\n     pupil           class            extrav            sex        \n Min.   : 1.00   Min.   :  1.00   Min.   : 1.000   Min.   :0.0000  \n 1st Qu.: 6.00   1st Qu.: 25.00   1st Qu.: 4.000   1st Qu.:0.0000  \n Median :11.00   Median : 51.00   Median : 5.000   Median :1.0000  \n Mean   :10.65   Mean   : 50.37   Mean   : 5.215   Mean   :0.5055  \n 3rd Qu.:16.00   3rd Qu.: 76.00   3rd Qu.: 6.000   3rd Qu.:1.0000  \n Max.   :26.00   Max.   :100.00   Max.   :10.000   Max.   :1.0000  \n      texp          popular     \n Min.   : 2.00   Min.   :0.000  \n 1st Qu.: 8.00   1st Qu.:4.100  \n Median :15.00   Median :5.100  \n Mean   :14.26   Mean   :5.076  \n 3rd Qu.:20.00   3rd Qu.:6.000  \n Max.   :25.00   Max.   :9.500  \n# A tibble: 6 × 6\n  pupil class extrav sex        texp popular\n  <dbl> <dbl>  <dbl> <dbl+lbl> <dbl>   <dbl>\n1     1     1      5 1 [girl]     24     6.3\n2     2     1      7 0 [boy]      24     4.9\n3     3     1      4 1 [girl]     24     5.3\n4     4     1      3 1 [girl]     24     4.7\n5     5     1      5 1 [girl]     24     6  \n6     6     1      4 0 [boy]      24     4.7\n```\n:::\n:::\n\n\n### A plot of the relationship of interest\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nggplot(data    = popular2data,\n       aes(x   = extrav,\n           y   = popular,\n           col = class))+ #to add the colours for different classes\n  geom_point(size     = 0.8,\n             alpha    = .8,\n             position = \"jitter\")+ #to add some random noise for plotting purposes\n  theme_minimal()+\n  theme(legend.position = \"none\")+\n  scale_color_gradientn(colours = rainbow(100))+\n  labs(title    = \"Popularity vs. Extraversion\",\n       subtitle = \"add colours for different classes\",\n       x = \"Extroversion\",\n       y = \"Average Popularity\")\n```\n````\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n### With the lines\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nggplot(data      = popular2data,\n       aes(x     = extrav,\n           y     = popular,\n           col   = class,\n           group = class))+ #to add the colours for different classes\n  geom_point(size     = 1.2,\n             alpha    = .8,\n             position = \"jitter\")+ #to add some random noise for plotting purposes\n  theme_minimal()+\n  theme(legend.position = \"none\")+\n  scale_color_gradientn(colours = rainbow(100))+\n  geom_smooth(method = lm,\n              se     = FALSE,\n              size   = .5, \n              alpha  = .8)+ # to add regression line\n  labs(title    = \"Popularity vs. Extraversion\",\n       subtitle = \"add colours for different classes and regression lines\",\n       x = \"Extroversion\",\n       y = \"Average Popularity\")\n```\n````\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n### A regression\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nggplot(data = popular2data, \n       aes(x   = extrav,\n           y   = popular, \n           col = as.factor(sex)))+\n  geom_point(size     = 1, \n             alpha    = .7, \n             position = \"jitter\")+\n  geom_smooth(method   = lm,\n              se       = T, \n              size     = 1.5, \n              linetype = 1, \n              alpha    = .7)+\n  theme_minimal()+\n  labs(title    = \"Popularity and Extraversion for 2 Genders\", \n       subtitle = \"The linear relationship between the two is similar for both genders\")+\n  scale_color_manual(name   =\" Gender\",\n                     labels = c(\"Boys\", \"Girls\"),\n                     values = c(\"lightblue\", \"pink\"))\n```\n````\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\nA model with random intercepts\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r, warning=FALSE, message=FALSE}}\nlibrary(lme4)\noptions(scipen=7)\nlibrary(lmerTest)\nmodel1 <- lmer(formula = popular ~ 1 + sex + extrav + (1|class), \n               data    = popular2data)\nsummary(model1)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: popular ~ 1 + sex + extrav + (1 | class)\n   Data: popular2data\n\nREML criterion at convergence: 4948.3\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.2091 -0.6575 -0.0044  0.6732  2.9755 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n class    (Intercept) 0.6272   0.7919  \n Residual             0.5921   0.7695  \nNumber of obs: 2000, groups:  class, 100\n\nFixed effects:\n              Estimate Std. Error         df t value Pr(>|t|)    \n(Intercept)    2.14096    0.11729  390.76822   18.25   <2e-16 ***\nsex            1.25300    0.03743 1926.69933   33.48   <2e-16 ***\nextrav         0.44161    0.01616 1956.77498   27.33   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n       (Intr) sex   \nsex    -0.100       \nextrav -0.705 -0.085\n```\n:::\n:::\n\n\nThough in this case, we probably do not need them but p-values can be obtained from `lmerTest`.  The standard `lme4` summary does not have them.\n\nNow let's add a **second-level** predictor.  Teacher experience does not vary within a given classroom, only across the 100 classrooms.  Let's look at this model.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nmodel2 <- lmer(popular ~ 1 + sex + extrav + texp + (1 | class), data=popular2data)\nsummary(model2)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: popular ~ 1 + sex + extrav + texp + (1 | class)\n   Data: popular2data\n\nREML criterion at convergence: 4885\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.1745 -0.6491 -0.0075  0.6705  3.0078 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n class    (Intercept) 0.2954   0.5435  \n Residual             0.5920   0.7694  \nNumber of obs: 2000, groups:  class, 100\n\nFixed effects:\n               Estimate  Std. Error          df t value  Pr(>|t|)    \n(Intercept)    0.809766    0.169993  226.431473   4.764 0.0000034 ***\nsex            1.253800    0.037290 1948.303018  33.623   < 2e-16 ***\nextrav         0.454431    0.016165 1954.889209  28.112   < 2e-16 ***\ntexp           0.088407    0.008764  101.627424  10.087   < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n       (Intr) sex    extrav\nsex    -0.040              \nextrav -0.589 -0.090       \ntexp   -0.802 -0.036  0.139\n```\n:::\n:::\n\n\nMore experienced teachers lead to higher reported average popularity.\n\n### Random slopes\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r, message=FALSE, warning=FALSE}}\nmodel3 <- lmer(formula = popular ~ 1 + sex + extrav + texp + (1 + sex + extrav | class),\n               data    = popular2data, control=lmerControl(optCtrl=list(maxfun=100000) ))\nsummary(model3)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: popular ~ 1 + sex + extrav + texp + (1 + sex + extrav | class)\n   Data: popular2data\nControl: lmerControl(optCtrl = list(maxfun = 100000))\n\nREML criterion at convergence: 4833.3\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.1643 -0.6554 -0.0246  0.6711  2.9570 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr       \n class    (Intercept) 1.342020 1.15846             \n          sex         0.002404 0.04903  -0.39      \n          extrav      0.034742 0.18639  -0.88 -0.09\n Residual             0.551435 0.74259             \nNumber of obs: 2000, groups:  class, 100\n\nFixed effects:\n              Estimate Std. Error         df t value Pr(>|t|)    \n(Intercept)   0.758511   0.197316 181.050469   3.844 0.000167 ***\nsex           1.250810   0.036942 986.050567  33.859  < 2e-16 ***\nextrav        0.452854   0.024645  96.208501  18.375  < 2e-16 ***\ntexp          0.089520   0.008618 101.321705  10.388  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n       (Intr) sex    extrav\nsex    -0.062              \nextrav -0.718 -0.066       \ntexp   -0.684 -0.039  0.089\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00597328 (tol = 0.002, component 1)\n```\n:::\n:::\n\n### Examining the Model\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nranova(model3)\n```\n````\n\n::: {.cell-output .cell-output-stderr}\n```\nboundary (singular) fit: see help('isSingular')\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nANOVA-like table for random-effects: Single term deletions\n\nModel:\npopular ~ sex + extrav + texp + (1 + sex + extrav | class)\n                                     npar  logLik    AIC    LRT Df\n<none>                                 11 -2416.6 4855.3          \nsex in (1 + sex + extrav | class)       8 -2417.4 4850.8  1.513  3\nextrav in (1 + sex + extrav | class)    8 -2441.9 4899.8 50.507  3\n                                           Pr(>Chisq)    \n<none>                                                   \nsex in (1 + sex + extrav | class)              0.6792    \nextrav in (1 + sex + extrav | class) 0.00000000006232 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nThe random effect associated with `sex` is not close to significance.\n\n### A Crossed-Effects Model\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nmodel5<-lmer(formula = popular ~ 1 + sex + extrav + texp+ extrav*texp + (1 + extrav | class), \n             data    = popular2data)\nsummary(model5)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: popular ~ 1 + sex + extrav + texp + extrav * texp + (1 + extrav |  \n    class)\n   Data: popular2data\n\nREML criterion at convergence: 4780.5\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-3.12872 -0.63857 -0.01129  0.67916  3.05006 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n class    (Intercept) 0.478639 0.69184       \n          extrav      0.005409 0.07355  -0.64\n Residual             0.552769 0.74348       \nNumber of obs: 2000, groups:  class, 100\n\nFixed effects:\n               Estimate  Std. Error          df t value Pr(>|t|)    \n(Intercept)   -1.209607    0.271901  109.345831  -4.449 2.09e-05 ***\nsex            1.240698    0.036233 1941.077365  34.243  < 2e-16 ***\nextrav         0.803578    0.040117   72.070164  20.031  < 2e-16 ***\ntexp           0.226197    0.016807   98.507109  13.458  < 2e-16 ***\nextrav:texp   -0.024728    0.002555   71.986847  -9.679 1.15e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) sex    extrav texp  \nsex          0.002                     \nextrav      -0.867 -0.065              \ntexp        -0.916 -0.047  0.801       \nextrav:texp  0.773  0.033 -0.901 -0.859\n```\n:::\n:::\n\n### A Picture\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nggplot(data = popular2data,\n       aes(x = extrav, \n           y = popular, \n           col = as.factor(texp)))+\n  viridis::scale_color_viridis(discrete = TRUE)+\n  geom_point(size     = .7,\n             alpha    = .8, \n             position = \"jitter\")+\n  geom_smooth(method = lm,\n              se     = FALSE,\n              size   = 1,\n              alpha  = .4)+\n  theme_minimal()+\n  labs(title    = \"Interaction btw. Experience and Extraversion\", \n       subtitle = \"The relationship changes\", \n       col      = \"Years of\\nTeacher\\nExperience\")\n```\n````\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n\n## Structural Equations Models\n\nA few weeks ago, Jack mentioned the use of principal components as a means for combining collinear variables.  There is a more general language for describing models of this sort.  The following example will play off of work I am currently finishing up with Elliot Maltz and a co-author.\n\nFirst, the data.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nlibrary(lavaan)\n```\n````\n\n::: {.cell-output .cell-output-stderr}\n```\nThis is lavaan 0.6-12\nlavaan is FREE software! Please report any bugs.\n```\n:::\n\n````{.cell-code}\n```{{r}}\nload(url(\"https://github.com/robertwwalker/ChoiceAndForecasting/raw/main/posts/week-5/data/EMData.RData\"))\n```\n````\n:::\n\n\nThere is a ton of data in here.  Let me pay particular attention to specific parts we are interested in.\n\n### Agentic\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nnames(EMData)[[76]]\ntable(EMData.Anonymous$...76)\nnames(EMData)[[77]]\ntable(EMData.Anonymous$...77)\nnames(EMData)[[78]]\ntable(EMData.Anonymous$...78)\nnames(EMData)[[79]]\ntable(EMData.Anonymous$...79)\nAB <- cfa('Agentic =~ ...76 + ...77 + ...78 + ...79', data=EMData.Anonymous, ordered = TRUE)\n```\n````\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in lav_model_vcov(lavmodel = lavmodel, lavsamplestats = lavsamplestats, : lavaan WARNING:\n    The variance-covariance matrix of the estimated parameters (vcov)\n    does not appear to be positive definite! The smallest eigenvalue\n    (= 6.642114e-18) is close to zero. This may be a symptom that the\n    model is not identified.\n```\n:::\n\n````{.cell-code}\n```{{r}}\nsummary(AB, fit.measures = TRUE, standardized = TRUE)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"28. You lack career guidance and support [People in the community expect you to be a leader]\"\n\n 1  2  3  4  5  6  7 \n22 18 22 21 12 15  5 \n[1] \"28. You lack career guidance and support [Your community encourages you to achieve individual success]\"\n\n 1  2  3  4  5  6  7 \n17 19 26 23 18 10  2 \n[1] \"28. You lack career guidance and support [You are expected to be assertive in your interactions with others]\"\n\n 1  2  3  4  5  6  7 \n13 27 27 31 11  4  2 \n[1] \"28. You lack career guidance and support [You are expected to have strong opinions]\"\n\n 1  2  3  4  5  6  7 \n11 26 19 31 23  3  2 \nlavaan 0.6-12 ended normally after 15 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        28\n\n  Number of observations                           115\n\nModel Test User Model:\n                                              Standard      Robust\n  Test Statistic                                 7.422      21.832\n  Degrees of freedom                                 2           2\n  P-value (Chi-square)                           0.024       0.000\n  Scaling correction factor                                  0.341\n  Shift parameter                                            0.087\n    simple second-order correction                                \n\nModel Test Baseline Model:\n\n  Test statistic                              2486.114    1657.812\n  Degrees of freedom                                 6           6\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.501\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.998       0.988\n  Tucker-Lewis Index (TLI)                       0.993       0.964\n                                                                  \n  Robust Comparative Fit Index (CFI)                            NA\n  Robust Tucker-Lewis Index (TLI)                               NA\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.154       0.295\n  90 Percent confidence interval - lower         0.047       0.191\n  90 Percent confidence interval - upper         0.280       0.412\n  P-value RMSEA <= 0.05                          0.053       0.000\n                                                                  \n  Robust RMSEA                                                  NA\n  90 Percent confidence interval - lower                        NA\n  90 Percent confidence interval - upper                        NA\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.033       0.033\n\nParameter Estimates:\n\n  Standard errors                           Robust.sem\n  Information                                 Expected\n  Information saturated (h1) model        Unstructured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  Agentic =~                                                            \n    ...76             1.000                               0.853    0.853\n    ...77             1.056    0.051   20.773    0.000    0.901    0.901\n    ...78             1.045    0.042   25.093    0.000    0.891    0.891\n    ...79             0.962    0.044   22.041    0.000    0.820    0.820\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   ....76             0.000                               0.000    0.000\n   ....77             0.000                               0.000    0.000\n   ....78             0.000                               0.000    0.000\n   ....79             0.000                               0.000    0.000\n    Agentic           0.000                               0.000    0.000\n\nThresholds:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n    ...76|t1         -0.873    0.135   -6.459    0.000   -0.873   -0.873\n    ...76|t2         -0.391    0.121   -3.241    0.001   -0.391   -0.391\n    ...76|t3          0.098    0.118    0.835    0.403    0.098    0.098\n    ...76|t4          0.588    0.125    4.702    0.000    0.588    0.588\n    ...76|t5          0.939    0.138    6.790    0.000    0.939    0.939\n    ...76|t6          1.712    0.207    8.262    0.000    1.712    1.712\n    ...77|t1         -1.046    0.144   -7.264    0.000   -1.046   -1.046\n    ...77|t2         -0.487    0.123   -3.975    0.000   -0.487   -0.487\n    ...77|t3          0.098    0.118    0.835    0.403    0.098    0.098\n    ...77|t4          0.641    0.127    5.062    0.000    0.641    0.641\n    ...77|t5          1.257    0.158    7.948    0.000    1.257    1.257\n    ...77|t6          2.111    0.285    7.411    0.000    2.111    2.111\n    ...78|t1         -1.211    0.155   -7.826    0.000   -1.211   -1.211\n    ...78|t2         -0.391    0.121   -3.241    0.001   -0.391   -0.391\n    ...78|t3          0.209    0.118    1.763    0.078    0.209    0.209\n    ...78|t4          1.046    0.144    7.264    0.000    1.046    1.046\n    ...78|t5          1.624    0.195    8.320    0.000    1.624    1.624\n    ...78|t6          2.111    0.285    7.411    0.000    2.111    2.111\n    ...79|t1         -1.307    0.162   -8.058    0.000   -1.307   -1.307\n    ...79|t2         -0.463    0.122   -3.792    0.000   -0.463   -0.463\n    ...79|t3         -0.033    0.117   -0.279    0.781   -0.033   -0.033\n    ...79|t4          0.695    0.128    5.418    0.000    0.695    0.695\n    ...79|t5          1.712    0.207    8.262    0.000    1.712    1.712\n    ...79|t6          2.111    0.285    7.411    0.000    2.111    2.111\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   ....76             0.273                               0.273    0.273\n   ....77             0.188                               0.188    0.188\n   ....78             0.207                               0.207    0.207\n   ....79             0.327                               0.327    0.327\n    Agentic           0.727    0.051   14.358    0.000    1.000    1.000\n\nScales y*:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n    ...76             1.000                               1.000    1.000\n    ...77             1.000                               1.000    1.000\n    ...78             1.000                               1.000    1.000\n    ...79             1.000                               1.000    1.000\n```\n:::\n:::\n\n\n\n### Communal\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nnames(EMData)[[80]]\ntable(EMData.Anonymous$...80)\nnames(EMData)[[81]]\ntable(EMData.Anonymous$...81)\nnames(EMData)[[84]]\ntable(EMData.Anonymous$...84)\nCB <- cfa('Communal =~ ...80 + ...81 + ...84', data=EMData.Anonymous, ordered = TRUE)\nsummary(CB, fit.measures = TRUE, standardized = TRUE)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"28. You lack career guidance and support [You are expected to be unselfish]\"\n\n 1  2  3  4  5  6  7 \n 5 13 24 25 25 19  4 \n[1] \"28. You lack career guidance and support [In your interactions with others you are expected to consider others opinions over your own]\"\n\n 1  2  3  4  5  6  7 \n 9 21 32 28 20  4  1 \n[1] \"28. You lack career guidance and support [Your community expects you to put others interests ahead of your own]\"\n\n 1  2  3  4  5  6  7 \n12 21 24 25 20 11  2 \nlavaan 0.6-12 ended normally after 13 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        21\n\n  Number of observations                           115\n\nModel Test User Model:\n                                              Standard      Robust\n  Test Statistic                                 0.000       0.000\n  Degrees of freedom                                 0           0\n\nModel Test Baseline Model:\n\n  Test statistic                               511.919     427.939\n  Degrees of freedom                                 3           3\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.198\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000       1.000\n  Tucker-Lewis Index (TLI)                       1.000       1.000\n                                                                  \n  Robust Comparative Fit Index (CFI)                            NA\n  Robust Tucker-Lewis Index (TLI)                               NA\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000       0.000\n  90 Percent confidence interval - lower         0.000       0.000\n  90 Percent confidence interval - upper         0.000       0.000\n  P-value RMSEA <= 0.05                             NA          NA\n                                                                  \n  Robust RMSEA                                                  NA\n  90 Percent confidence interval - lower                     0.000\n  90 Percent confidence interval - upper                     0.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.000       0.000\n\nParameter Estimates:\n\n  Standard errors                           Robust.sem\n  Information                                 Expected\n  Information saturated (h1) model        Unstructured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  Communal =~                                                           \n    ...80             1.000                               0.823    0.823\n    ...81             0.908    0.078   11.572    0.000    0.747    0.747\n    ...84             0.983    0.083   11.823    0.000    0.808    0.808\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   ....80             0.000                               0.000    0.000\n   ....81             0.000                               0.000    0.000\n   ....84             0.000                               0.000    0.000\n    Communal          0.000                               0.000    0.000\n\nThresholds:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n    ...80|t1         -1.712    0.207   -8.262    0.000   -1.712   -1.712\n    ...80|t2         -1.009    0.142   -7.110    0.000   -1.009   -1.009\n    ...80|t3         -0.345    0.120   -2.872    0.004   -0.345   -0.345\n    ...80|t4          0.209    0.118    1.763    0.078    0.209    0.209\n    ...80|t5          0.842    0.134    6.289    0.000    0.842    0.842\n    ...80|t6          1.815    0.223    8.129    0.000    1.815    1.815\n    ...81|t1         -1.417    0.172   -8.235    0.000   -1.417   -1.417\n    ...81|t2         -0.641    0.127   -5.062    0.000   -0.641   -0.641\n    ...81|t3          0.098    0.118    0.835    0.403    0.098    0.098\n    ...81|t4          0.781    0.131    5.945    0.000    0.781    0.781\n    ...81|t5          1.712    0.207    8.262    0.000    1.712    1.712\n    ...81|t6          2.378    0.369    6.451    0.000    2.378    2.378\n    ...84|t1         -1.257    0.158   -7.948    0.000   -1.257   -1.257\n    ...84|t2         -0.562    0.124   -4.521    0.000   -0.562   -0.562\n    ...84|t3         -0.011    0.117   -0.093    0.926   -0.011   -0.011\n    ...84|t4          0.562    0.124    4.521    0.000    0.562    0.562\n    ...84|t5          1.211    0.155    7.826    0.000    1.211    1.211\n    ...84|t6          2.111    0.285    7.411    0.000    2.111    2.111\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   ....80             0.323                               0.323    0.323\n   ....81             0.443                               0.443    0.443\n   ....84             0.347                               0.347    0.347\n    Communal          0.677    0.072    9.442    0.000    1.000    1.000\n\nScales y*:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n    ...80             1.000                               1.000    1.000\n    ...81             1.000                               1.000    1.000\n    ...84             1.000                               1.000    1.000\n```\n:::\n:::\n\n\n\n### Mentoring\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nnames(EMData)[[13]]\ntable(EMData.Anonymous$...13)\nnames(EMData)[[14]]\ntable(EMData.Anonymous$...14)\nnames(EMData)[[15]]\ntable(EMData.Anonymous$...15)\nM <- cfa('Mentoring =~ ...13 + ...14 + ...15', data=EMData.Anonymous, ordered = TRUE)\nsummary(M, fit.measures = TRUE, standardized = TRUE)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"5. On a scale of 7 to 1, with 7 being very regularly and 1 being very rarely, how regularly do you:  [Encourage entrepreneurs to start businesses]\"\n\n 1  2  3  4  5  6  7 \n21 27 12 14 10 26  5 \n[1] \"5. On a scale of 7 to 1, with 7 being very regularly and 1 being very rarely, how regularly do you:  [Reassure other entrepreneurs when things are not going well]\"\n\n 1  2  3  4  5  6  7 \n22 21 10 19 33  4  6 \n[1] \"5. On a scale of 7 to 1, with 7 being very regularly and 1 being very rarely, how regularly do you:  [Help other entrepreneurs have confidence they can succeed]\"\n\n 1  2  3  4  5  6  7 \n21 29 27 11 21  5  1 \nlavaan 0.6-12 ended normally after 10 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        21\n\n  Number of observations                           115\n\nModel Test User Model:\n                                              Standard      Robust\n  Test Statistic                                 0.000       0.000\n  Degrees of freedom                                 0           0\n\nModel Test Baseline Model:\n\n  Test statistic                              1726.590    1624.559\n  Degrees of freedom                                 3           3\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.063\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000       1.000\n  Tucker-Lewis Index (TLI)                       1.000       1.000\n                                                                  \n  Robust Comparative Fit Index (CFI)                            NA\n  Robust Tucker-Lewis Index (TLI)                               NA\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000       0.000\n  90 Percent confidence interval - lower         0.000       0.000\n  90 Percent confidence interval - upper         0.000       0.000\n  P-value RMSEA <= 0.05                             NA          NA\n                                                                  \n  Robust RMSEA                                                  NA\n  90 Percent confidence interval - lower                     0.000\n  90 Percent confidence interval - upper                     0.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.000       0.000\n\nParameter Estimates:\n\n  Standard errors                           Robust.sem\n  Information                                 Expected\n  Information saturated (h1) model        Unstructured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  Mentoring =~                                                          \n    ...13             1.000                               0.981    0.981\n    ...14             0.879    0.058   15.193    0.000    0.862    0.862\n    ...15             0.844    0.056   15.063    0.000    0.827    0.827\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   ....13             0.000                               0.000    0.000\n   ....14             0.000                               0.000    0.000\n   ....15             0.000                               0.000    0.000\n    Mentoring         0.000                               0.000    0.000\n\nThresholds:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n    ...13|t1         -0.905    0.137   -6.626    0.000   -0.905   -0.905\n    ...13|t2         -0.209    0.118   -1.763    0.078   -0.209   -0.209\n    ...13|t3          0.055    0.117    0.464    0.643    0.055    0.055\n    ...13|t4          0.368    0.120    3.057    0.002    0.368    0.368\n    ...13|t5          0.614    0.126    4.882    0.000    0.614    0.614\n    ...13|t6          1.712    0.207    8.262    0.000    1.712    1.712\n    ...14|t1         -0.873    0.135   -6.459    0.000   -0.873   -0.873\n    ...14|t2         -0.322    0.120   -2.688    0.007   -0.322   -0.322\n    ...14|t3         -0.098    0.118   -0.835    0.403   -0.098   -0.098\n    ...14|t4          0.322    0.120    2.688    0.007    0.322    0.322\n    ...14|t5          1.360    0.167    8.155    0.000    1.360    1.360\n    ...14|t6          1.624    0.195    8.320    0.000    1.624    1.624\n    ...15|t1         -0.905    0.137   -6.626    0.000   -0.905   -0.905\n    ...15|t2         -0.164    0.118   -1.392    0.164   -0.164   -0.164\n    ...15|t3          0.439    0.122    3.608    0.000    0.439    0.439\n    ...15|t4          0.723    0.129    5.595    0.000    0.723    0.723\n    ...15|t5          1.624    0.195    8.320    0.000    1.624    1.624\n    ...15|t6          2.378    0.369    6.451    0.000    2.378    2.378\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   ....13             0.039                               0.039    0.039\n   ....14             0.258                               0.258    0.258\n   ....15             0.315                               0.315    0.315\n    Mentoring         0.961    0.077   12.508    0.000    1.000    1.000\n\nScales y*:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n    ...13             1.000                               1.000    1.000\n    ...14             1.000                               1.000    1.000\n    ...15             1.000                               1.000    1.000\n```\n:::\n:::\n\n\n\n### Social Influence\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nnames(EMData)[[37]]\ntable(EMData.Anonymous$...37)\nnames(EMData)[[38]]\ntable(EMData.Anonymous$...38)\nnames(EMData)[[39]]\ntable(EMData.Anonymous$...39)\nSI <- cfa('Social.Influence =~ ...37 + ...38 + ...39', data=EMData.Anonymous, ordered = TRUE)\nsummary(SI, fit.measures = TRUE, standardized = TRUE)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"11. On a scale of 7 to 1, with 7 being strongly agree and 1 being strongly disagree, please indicate your level of agreement with the following items relating to your community:  [The respect you have in the community helps your business]\"\n\n 1  2  3  4  5  6 \n26 38 31  5  8  7 \n[1] \"11. On a scale of 7 to 1, with 7 being strongly agree and 1 being strongly disagree, please indicate your level of agreement with the following items relating to your community:  [Your understanding of the community helps your business]\"\n\n 1  2  3  4  5  6 \n27 40 28  6  7  7 \n[1] \"11. On a scale of 7 to 1, with 7 being strongly agree and 1 being strongly disagree, please indicate your level of agreement with the following items relating to your community:  [Your influence in the community helps your business]\"\n\n 1  2  3  4  5  6  7 \n30 38 30  4  7  5  1 \nlavaan 0.6-12 ended normally after 12 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                        19\n\n  Number of observations                           115\n\nModel Test User Model:\n                                              Standard      Robust\n  Test Statistic                                 0.000       0.000\n  Degrees of freedom                                 0           0\n\nModel Test Baseline Model:\n\n  Test statistic                              3636.699    2922.199\n  Degrees of freedom                                 3           3\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.245\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000       1.000\n  Tucker-Lewis Index (TLI)                       1.000       1.000\n                                                                  \n  Robust Comparative Fit Index (CFI)                            NA\n  Robust Tucker-Lewis Index (TLI)                               NA\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000       0.000\n  90 Percent confidence interval - lower         0.000       0.000\n  90 Percent confidence interval - upper         0.000       0.000\n  P-value RMSEA <= 0.05                             NA          NA\n                                                                  \n  Robust RMSEA                                                  NA\n  90 Percent confidence interval - lower                     0.000\n  90 Percent confidence interval - upper                     0.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.000       0.000\n\nParameter Estimates:\n\n  Standard errors                           Robust.sem\n  Information                                 Expected\n  Information saturated (h1) model        Unstructured\n\nLatent Variables:\n                      Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  Social.Influence =~                                                      \n    ...37                1.000                               0.928    0.928\n    ...38                1.055    0.031   33.595    0.000    0.979    0.979\n    ...39                0.942    0.029   32.441    0.000    0.874    0.874\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   ....37             0.000                               0.000    0.000\n   ....38             0.000                               0.000    0.000\n   ....39             0.000                               0.000    0.000\n    Social.Influnc    0.000                               0.000    0.000\n\nThresholds:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n    ...37|t1         -0.752    0.130   -5.771    0.000   -0.752   -0.752\n    ...37|t2          0.142    0.118    1.207    0.228    0.142    0.142\n    ...37|t3          0.939    0.138    6.790    0.000    0.939    0.939\n    ...37|t4          1.124    0.149    7.558    0.000    1.124    1.124\n    ...37|t5          1.548    0.186    8.325    0.000    1.548    1.548\n    ...38|t1         -0.723    0.129   -5.595    0.000   -0.723   -0.723\n    ...38|t2          0.209    0.118    1.763    0.078    0.209    0.209\n    ...38|t3          0.939    0.138    6.790    0.000    0.939    0.939\n    ...38|t4          1.166    0.152    7.696    0.000    1.166    1.166\n    ...38|t5          1.548    0.186    8.325    0.000    1.548    1.548\n    ...39|t1         -0.641    0.127   -5.062    0.000   -0.641   -0.641\n    ...39|t2          0.231    0.119    1.948    0.051    0.231    0.231\n    ...39|t3          1.046    0.144    7.264    0.000    1.046    1.046\n    ...39|t4          1.211    0.155    7.826    0.000    1.211    1.211\n    ...39|t5          1.624    0.195    8.320    0.000    1.624    1.624\n    ...39|t6          2.378    0.369    6.451    0.000    2.378    2.378\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   ....37             0.139                               0.139    0.139\n   ....38             0.041                               0.041    0.041\n   ....39             0.236                               0.236    0.236\n    Social.Influnc    0.861    0.034   25.088    0.000    1.000    1.000\n\nScales y*:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n    ...37             1.000                               1.000    1.000\n    ...38             1.000                               1.000    1.000\n    ...39             1.000                               1.000    1.000\n```\n:::\n:::\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nlibrary(lavaanPlot)\nlavaanPlot(model = SI, node_options = list(shape = \"box\", fontname = \"Helvetica\"), edge_options = list(color = \"grey\"), coefs = TRUE, covs = TRUE)\n```\n````\n\n::: {.cell-output-display}\n```{=html}\n<div id=\"htmlwidget-77f47cc95437c4500f22\" style=\"width:100%;height:464px;\" class=\"grViz html-widget\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-77f47cc95437c4500f22\">{\"x\":{\"diagram\":\" digraph plot { \\n graph [ overlap = true, fontsize = 10 ] \\n node [ shape = box, fontname = Helvetica ] \\n node [shape = box] \\n 37; 38; 39 \\n node [shape = oval] \\n SocialInfluence \\n \\n edge [ color = grey ] \\n  SocialInfluence->37 [label = \\\"1\\\"] SocialInfluence->38 [label = \\\"1.06\\\"] SocialInfluence->39 [label = \\\"0.94\\\"] \\n}\",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n:::\n:::\n\n\n\n### An SEM\n\nNow let me combine those `measurement` models to produce a set of two structural equations.  I wish to explain income and employment given these factors.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r, warning=FALSE, message=FALSE}}\nnames(EMData)[c(5,59)]\nStruct <- sem('Agentic =~ ...76 + ...77 + ...78 + ...79\n          Communal =~ ...80 + ...81 + ...84\n          Mentoring =~ ...13 + ...14 + ...15\n          Social.Influence =~ ...37 + ...38 + ...39\n          ...59 ~ Agentic + Communal + Mentoring + Social.Influence\n          ...5 ~ Agentic + Communal + Mentoring + Social.Influence', data=EMData.Anonymous, ordered = c(\"...13\",\"...14\", \"...15\", \"...80\",\"...81\", \"...84\", \"...76\",\"...77\", \"...78\", \"...79\",\"...37\", \"...38\", \"...39\"))\nsummary(Struct, fit.measures=TRUE, standardized=TRUE)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"3. What is the current income generated from the business? (USD PM)\"\n[2] \"20. How many people do you manage in your business?\"                \nlavaan 0.6-12 ended normally after 112 iterations\n\n  Estimator                                       DWLS\n  Optimization method                           NLMINB\n  Number of model parameters                       108\n\n  Number of observations                           115\n\nModel Test User Model:\n                                              Standard      Robust\n  Test Statistic                               176.253     255.843\n  Degrees of freedom                                77          77\n  P-value (Chi-square)                           0.000       0.000\n  Scaling correction factor                                  0.804\n  Shift parameter                                           36.682\n    simple second-order correction                                \n\nModel Test Baseline Model:\n\n  Test statistic                              9489.339    3694.019\n  Degrees of freedom                               105         105\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  2.615\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.989       0.950\n  Tucker-Lewis Index (TLI)                       0.986       0.932\n                                                                  \n  Robust Comparative Fit Index (CFI)                            NA\n  Robust Tucker-Lewis Index (TLI)                               NA\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.106       0.143\n  90 Percent confidence interval - lower         0.086       0.124\n  90 Percent confidence interval - upper         0.127       0.162\n  P-value RMSEA <= 0.05                          0.000       0.000\n                                                                  \n  Robust RMSEA                                                  NA\n  90 Percent confidence interval - lower                        NA\n  90 Percent confidence interval - upper                        NA\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.075       0.075\n\nParameter Estimates:\n\n  Standard errors                           Robust.sem\n  Information                                 Expected\n  Information saturated (h1) model        Unstructured\n\nLatent Variables:\n                      Estimate   Std.Err  z-value  P(>|z|)   Std.lv   Std.all\n  Agentic =~                                                                 \n    ...76                 1.000                                0.812    0.812\n    ...77                 1.110    0.051   21.573    0.000     0.901    0.901\n    ...78                 1.076    0.044   24.545    0.000     0.873    0.873\n    ...79                 1.097    0.047   23.283    0.000     0.890    0.890\n  Communal =~                                                                \n    ...80                 1.000                                0.715    0.715\n    ...81                 1.233    0.126    9.803    0.000     0.881    0.881\n    ...84                 1.103    0.091   12.190    0.000     0.788    0.788\n  Mentoring =~                                                               \n    ...13                 1.000                                0.961    0.961\n    ...14                 0.908    0.057   15.897    0.000     0.872    0.872\n    ...15                 0.876    0.054   16.228    0.000     0.842    0.842\n  Social.Influence =~                                                        \n    ...37                 1.000                                0.948    0.948\n    ...38                 1.004    0.030   33.882    0.000     0.952    0.952\n    ...39                 0.941    0.029   32.029    0.000     0.892    0.892\n\nRegressions:\n                   Estimate   Std.Err  z-value  P(>|z|)   Std.lv   Std.all\n  ...59 ~                                                                 \n    Agentic           -0.087    0.063   -1.386    0.166    -0.071   -0.052\n    Communal           0.119    0.108    1.100    0.271     0.085    0.062\n    Mentoring          0.166    0.075    2.213    0.027     0.159    0.116\n    Social.Influnc    -0.422    0.055   -7.620    0.000    -0.400   -0.292\n  ...5 ~                                                                  \n    Agentic           51.893   19.705    2.633    0.008    42.118    0.205\n    Communal          -9.427   20.599   -0.458    0.647    -6.736   -0.033\n    Mentoring          1.218   15.046    0.081    0.935     1.170    0.006\n    Social.Influnc    35.014   16.427    2.131    0.033    33.195    0.161\n\nCovariances:\n                   Estimate   Std.Err  z-value  P(>|z|)   Std.lv   Std.all\n  Agentic ~~                                                              \n    Communal           0.259    0.044    5.821    0.000     0.447    0.447\n    Mentoring          0.203    0.062    3.269    0.001     0.261    0.261\n    Social.Influnc     0.247    0.056    4.423    0.000     0.321    0.321\n  Communal ~~                                                             \n    Mentoring          0.134    0.057    2.329    0.020     0.195    0.195\n    Social.Influnc     0.308    0.062    4.963    0.000     0.454    0.454\n  Mentoring ~~                                                            \n    Social.Influnc     0.067    0.074    0.904    0.366     0.074    0.074\n ....59 ~~                                                                \n   ....5              78.509   19.599    4.006    0.000    78.509    0.304\n\nIntercepts:\n                   Estimate   Std.Err  z-value  P(>|z|)   Std.lv   Std.all\n   ....76              0.000                                0.000    0.000\n   ....77              0.000                                0.000    0.000\n   ....78              0.000                                0.000    0.000\n   ....79              0.000                                0.000    0.000\n   ....80              0.000                                0.000    0.000\n   ....81              0.000                                0.000    0.000\n   ....84              0.000                                0.000    0.000\n   ....13              0.000                                0.000    0.000\n   ....14              0.000                                0.000    0.000\n   ....15              0.000                                0.000    0.000\n   ....37              0.000                                0.000    0.000\n   ....38              0.000                                0.000    0.000\n   ....39              0.000                                0.000    0.000\n   ....59              0.435    0.305    1.427    0.154     0.435    0.317\n   ....5             380.609   23.778   16.007    0.000   380.609    1.849\n    Agentic            0.000                                0.000    0.000\n    Communal           0.000                                0.000    0.000\n    Mentoring          0.000                                0.000    0.000\n    Social.Influnc     0.000                                0.000    0.000\n\nThresholds:\n                   Estimate   Std.Err  z-value  P(>|z|)   Std.lv   Std.all\n    ...76|t1          -0.873    0.135   -6.459    0.000    -0.873   -0.873\n    ...76|t2          -0.391    0.121   -3.241    0.001    -0.391   -0.391\n    ...76|t3           0.098    0.118    0.835    0.403     0.098    0.098\n    ...76|t4           0.588    0.125    4.702    0.000     0.588    0.588\n    ...76|t5           0.939    0.138    6.790    0.000     0.939    0.939\n    ...76|t6           1.712    0.207    8.262    0.000     1.712    1.712\n    ...77|t1          -1.046    0.144   -7.264    0.000    -1.046   -1.046\n    ...77|t2          -0.487    0.123   -3.975    0.000    -0.487   -0.487\n    ...77|t3           0.098    0.118    0.835    0.403     0.098    0.098\n    ...77|t4           0.641    0.127    5.062    0.000     0.641    0.641\n    ...77|t5           1.257    0.158    7.948    0.000     1.257    1.257\n    ...77|t6           2.111    0.285    7.411    0.000     2.111    2.111\n    ...78|t1          -1.211    0.155   -7.826    0.000    -1.211   -1.211\n    ...78|t2          -0.391    0.121   -3.241    0.001    -0.391   -0.391\n    ...78|t3           0.209    0.118    1.763    0.078     0.209    0.209\n    ...78|t4           1.046    0.144    7.264    0.000     1.046    1.046\n    ...78|t5           1.624    0.195    8.320    0.000     1.624    1.624\n    ...78|t6           2.111    0.285    7.411    0.000     2.111    2.111\n    ...79|t1          -1.307    0.162   -8.058    0.000    -1.307   -1.307\n    ...79|t2          -0.463    0.122   -3.792    0.000    -0.463   -0.463\n    ...79|t3          -0.033    0.117   -0.279    0.781    -0.033   -0.033\n    ...79|t4           0.695    0.128    5.418    0.000     0.695    0.695\n    ...79|t5           1.712    0.207    8.262    0.000     1.712    1.712\n    ...79|t6           2.111    0.285    7.411    0.000     2.111    2.111\n    ...80|t1          -1.712    0.207   -8.262    0.000    -1.712   -1.712\n    ...80|t2          -1.009    0.142   -7.110    0.000    -1.009   -1.009\n    ...80|t3          -0.345    0.120   -2.872    0.004    -0.345   -0.345\n    ...80|t4           0.209    0.118    1.763    0.078     0.209    0.209\n    ...80|t5           0.842    0.134    6.289    0.000     0.842    0.842\n    ...80|t6           1.815    0.223    8.129    0.000     1.815    1.815\n    ...81|t1          -1.417    0.172   -8.235    0.000    -1.417   -1.417\n    ...81|t2          -0.641    0.127   -5.062    0.000    -0.641   -0.641\n    ...81|t3           0.098    0.118    0.835    0.403     0.098    0.098\n    ...81|t4           0.781    0.131    5.945    0.000     0.781    0.781\n    ...81|t5           1.712    0.207    8.262    0.000     1.712    1.712\n    ...81|t6           2.378    0.369    6.451    0.000     2.378    2.378\n    ...84|t1          -1.257    0.158   -7.948    0.000    -1.257   -1.257\n    ...84|t2          -0.562    0.124   -4.521    0.000    -0.562   -0.562\n    ...84|t3          -0.011    0.117   -0.093    0.926    -0.011   -0.011\n    ...84|t4           0.562    0.124    4.521    0.000     0.562    0.562\n    ...84|t5           1.211    0.155    7.826    0.000     1.211    1.211\n    ...84|t6           2.111    0.285    7.411    0.000     2.111    2.111\n    ...13|t1          -0.905    0.137   -6.626    0.000    -0.905   -0.905\n    ...13|t2          -0.209    0.118   -1.763    0.078    -0.209   -0.209\n    ...13|t3           0.055    0.117    0.464    0.643     0.055    0.055\n    ...13|t4           0.368    0.120    3.057    0.002     0.368    0.368\n    ...13|t5           0.614    0.126    4.882    0.000     0.614    0.614\n    ...13|t6           1.712    0.207    8.262    0.000     1.712    1.712\n    ...14|t1          -0.873    0.135   -6.459    0.000    -0.873   -0.873\n    ...14|t2          -0.322    0.120   -2.688    0.007    -0.322   -0.322\n    ...14|t3          -0.098    0.118   -0.835    0.403    -0.098   -0.098\n    ...14|t4           0.322    0.120    2.688    0.007     0.322    0.322\n    ...14|t5           1.360    0.167    8.155    0.000     1.360    1.360\n    ...14|t6           1.624    0.195    8.320    0.000     1.624    1.624\n    ...15|t1          -0.905    0.137   -6.626    0.000    -0.905   -0.905\n    ...15|t2          -0.164    0.118   -1.392    0.164    -0.164   -0.164\n    ...15|t3           0.439    0.122    3.608    0.000     0.439    0.439\n    ...15|t4           0.723    0.129    5.595    0.000     0.723    0.723\n    ...15|t5           1.624    0.195    8.320    0.000     1.624    1.624\n    ...15|t6           2.378    0.369    6.451    0.000     2.378    2.378\n    ...37|t1          -0.752    0.130   -5.771    0.000    -0.752   -0.752\n    ...37|t2           0.142    0.118    1.207    0.228     0.142    0.142\n    ...37|t3           0.939    0.138    6.790    0.000     0.939    0.939\n    ...37|t4           1.124    0.149    7.558    0.000     1.124    1.124\n    ...37|t5           1.548    0.186    8.325    0.000     1.548    1.548\n    ...38|t1          -0.723    0.129   -5.595    0.000    -0.723   -0.723\n    ...38|t2           0.209    0.118    1.763    0.078     0.209    0.209\n    ...38|t3           0.939    0.138    6.790    0.000     0.939    0.939\n    ...38|t4           1.166    0.152    7.696    0.000     1.166    1.166\n    ...38|t5           1.548    0.186    8.325    0.000     1.548    1.548\n    ...39|t1          -0.641    0.127   -5.062    0.000    -0.641   -0.641\n    ...39|t2           0.231    0.119    1.948    0.051     0.231    0.231\n    ...39|t3           1.046    0.144    7.264    0.000     1.046    1.046\n    ...39|t4           1.211    0.155    7.826    0.000     1.211    1.211\n    ...39|t5           1.624    0.195    8.320    0.000     1.624    1.624\n    ...39|t6           2.378    0.369    6.451    0.000     2.378    2.378\n\nVariances:\n                   Estimate   Std.Err  z-value  P(>|z|)   Std.lv   Std.all\n   ....76              0.341                                0.341    0.341\n   ....77              0.188                                0.188    0.188\n   ....78              0.238                                0.238    0.238\n   ....79              0.207                                0.207    0.207\n   ....80              0.489                                0.489    0.489\n   ....81              0.224                                0.224    0.224\n   ....84              0.378                                0.378    0.378\n   ....13              0.077                                0.077    0.077\n   ....14              0.239                                0.239    0.239\n   ....15              0.292                                0.292    0.292\n   ....37              0.101                                0.101    0.101\n   ....38              0.094                                0.094    0.094\n   ....39              0.204                                0.204    0.204\n   ....59              1.711    0.147   11.666    0.000     1.711    0.910\n   ....5           38984.352 4516.263    8.632    0.000 38984.352    0.920\n    Agentic            0.659    0.048   13.761    0.000     1.000    1.000\n    Communal           0.511    0.068    7.492    0.000     1.000    1.000\n    Mentoring          0.923    0.072   12.824    0.000     1.000    1.000\n    Social.Influnc     0.899    0.033   27.070    0.000     1.000    1.000\n\nScales y*:\n                   Estimate   Std.Err  z-value  P(>|z|)   Std.lv   Std.all\n    ...76              1.000                                1.000    1.000\n    ...77              1.000                                1.000    1.000\n    ...78              1.000                                1.000    1.000\n    ...79              1.000                                1.000    1.000\n    ...80              1.000                                1.000    1.000\n    ...81              1.000                                1.000    1.000\n    ...84              1.000                                1.000    1.000\n    ...13              1.000                                1.000    1.000\n    ...14              1.000                                1.000    1.000\n    ...15              1.000                                1.000    1.000\n    ...37              1.000                                1.000    1.000\n    ...38              1.000                                1.000    1.000\n    ...39              1.000                                1.000    1.000\n```\n:::\n:::\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nlavaanPlot(model=Struct, node_options = list(shape = \"box\", fontname = \"Helvetica\"), edge_options = list(color = \"grey\"), coefs = TRUE, covs = TRUE)\n```\n````\n\n::: {.cell-output-display}\n```{=html}\n<div id=\"htmlwidget-b4f19a1555eca13b271d\" style=\"width:100%;height:464px;\" class=\"grViz html-widget\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-b4f19a1555eca13b271d\">{\"x\":{\"diagram\":\" digraph plot { \\n graph [ overlap = true, fontsize = 10 ] \\n node [ shape = box, fontname = Helvetica ] \\n node [shape = box] \\n 59; 5; 76; 77; 78; 79; 80; 81; 84; 13; 14; 15; 37; 38; 39 \\n node [shape = oval] \\n Agentic; Communal; Mentoring; SocialInfluence \\n \\n edge [ color = grey ] \\n Agentic->59 [label = \\\"-0.09\\\"] Communal->59 [label = \\\"0.12\\\"] Mentoring->59 [label = \\\"0.17\\\"] SocialInfluence->59 [label = \\\"-0.42\\\"] Agentic->5 [label = \\\"51.89\\\"] Communal->5 [label = \\\"-9.43\\\"] Mentoring->5 [label = \\\"1.22\\\"] SocialInfluence->5 [label = \\\"35.01\\\"] Agentic->76 [label = \\\"1\\\"] Agentic->77 [label = \\\"1.11\\\"] Agentic->78 [label = \\\"1.08\\\"] Agentic->79 [label = \\\"1.1\\\"] Communal->80 [label = \\\"1\\\"] Communal->81 [label = \\\"1.23\\\"] Communal->84 [label = \\\"1.1\\\"] Mentoring->13 [label = \\\"1\\\"] Mentoring->14 [label = \\\"0.91\\\"] Mentoring->15 [label = \\\"0.88\\\"] SocialInfluence->37 [label = \\\"1\\\"] SocialInfluence->38 [label = \\\"1\\\"] SocialInfluence->39 [label = \\\"0.94\\\"] Communal -> Agentic [label = \\\"0.26\\\", dir = \\\"both\\\"] Mentoring -> Agentic [label = \\\"0.2\\\", dir = \\\"both\\\"] SocialInfluence -> Agentic [label = \\\"0.25\\\", dir = \\\"both\\\"] Mentoring -> Communal [label = \\\"0.13\\\", dir = \\\"both\\\"] SocialInfluence -> Communal [label = \\\"0.31\\\", dir = \\\"both\\\"] SocialInfluence -> Mentoring [label = \\\"0.07\\\", dir = \\\"both\\\"] 5 -> 59 [label = \\\"78.51\\\", dir = \\\"both\\\"]\\n}\",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/htmlwidgets-1.5.4/htmlwidgets.js\"></script>\n<script src=\"../../site_libs/viz-1.8.2/viz.js\"></script>\n<link href=\"../../site_libs/DiagrammeR-styles-0.2/styles.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/grViz-binding-1.0.9/grViz.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}